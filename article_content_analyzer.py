#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“° ê°œë³„ ê¸°ì‚¬ ì‹¬ì¸µ ë¶„ì„ê¸°
- ê¸°ì‚¬ ë‚´ìš©ì„ ëŒ€ì£¼ì œì™€ ì†Œì£¼ì œë¡œ êµ¬ì¡°í™”
- í•µì‹¬ ì •ë³´ ì¶”ì¶œ ë° ì •ë¦¬
"""

import re
from typing import Dict, List, Any
from collections import Counter

class ArticleContentAnalyzer:
    """ê°œë³„ ê¸°ì‚¬ë¥¼ ì‹¬ì¸µ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.section_keywords = {
            'ë°°ê²½': ['ë°°ê²½', 'í˜„í™©', 'ìƒí™©', 'ë¬¸ì œ', 'ì´ìŠˆ'],
            'í•µì‹¬ë‚´ìš©': ['ë°œí‘œ', 'ê°œë°œ', 'ë„ì…', 'ì¶”ì§„', 'ì‹œí–‰', 'ê³„íš'],
            'íš¨ê³¼': ['íš¨ê³¼', 'ê¸°ëŒ€', 'ì „ë§', 'ì˜ˆìƒ', 'ëª©í‘œ', 'ì„±ê³¼'],
            'ì„¸ë¶€ì‚¬í•­': ['êµ¬ì²´ì ', 'ì„¸ë¶€', 'ë‚´ìš©', 'ë°©ì•ˆ', 'ê³„íš'],
            'ì˜ë¯¸': ['ì˜ë¯¸', 'ì¤‘ìš”', 'ì˜ì˜', 'ê°€ì¹˜', 'ì˜í–¥']
        }
        
    def analyze_article(self, article: Dict[str, Any]) -> Dict[str, Any]:
        """ê°œë³„ ê¸°ì‚¬ë¥¼ ì‹¬ì¸µ ë¶„ì„"""
        
        # ê¸°ë³¸ ì •ë³´
        title = article.get('title', '')
        summary = article.get('summary', '')
        key_points = article.get('key_points', '')
        content = f"{title} {summary} {key_points}"
        
        # ë¶„ì„ ìˆ˜í–‰
        analysis = {
            'original': article,
            'main_theme': self._extract_main_theme(title, summary),
            'sub_themes': self._extract_sub_themes(content),
            'key_facts': self._extract_key_facts(key_points),
            'structure': self._analyze_structure(content),
            'entities': self._extract_entities(content),
            'numbers': self._extract_numbers(content)
        }
        
        return analysis
    
    def _extract_main_theme(self, title: str, summary: str) -> Dict[str, str]:
        """ëŒ€ì£¼ì œ ì¶”ì¶œ"""
        
        # ì œëª©ì—ì„œ í•µì‹¬ ë™ì‚¬/ëª…ì‚¬ ì¶”ì¶œ
        main_action = ''
        main_subject = ''
        
        # ë™ì‚¬ íŒ¨í„´
        action_patterns = [
            r'(\w+) ë°œí‘œ', r'(\w+) ì¶”ì§„', r'(\w+) ë„ì…', 
            r'(\w+) ê°œë°œ', r'(\w+) êµ¬ì¶•', r'(\w+) ì‹œí–‰',
            r'(\w+) ê°•í™”', r'(\w+) í™•ëŒ€', r'(\w+) ê°œì„ '
        ]
        
        for pattern in action_patterns:
            match = re.search(pattern, title)
            if match:
                main_action = match.group(0)
                break
                
        # ì£¼ì²´ ì¶”ì¶œ (ê¸°ê´€, ê¸°ì—…ëª…)
        entities = re.findall(r'([ê°€-í£]+(?:ì „ë ¥|ì—ë„ˆì§€|ê¸°ìˆ |ì‚°ì—…|ê³µì‚¬|ì²­|ë¶€|ì›|ë‹¨))', title)
        if entities:
            main_subject = entities[0]
            
        # ëŒ€ì£¼ì œ êµ¬ì„±
        if main_action and main_subject:
            theme = f"{main_subject}ì˜ {main_action}"
        elif main_action:
            theme = main_action
        else:
            # ì œëª©ì˜ ì²« êµ¬ì ˆì„ ëŒ€ì£¼ì œë¡œ
            theme = title.split(',')[0].split('...')[0]
            
        return {
            'theme': theme,
            'category': self._categorize_theme(title),
            'focus': self._identify_focus(title, summary)
        }
    
    def _extract_sub_themes(self, content: str) -> List[Dict[str, str]]:
        """ì†Œì£¼ì œ ì¶”ì¶œ (3-4ê°œ)"""
        
        sub_themes = []
        
        # 1. ë¬¸ì¥ì„ ë¶„ì„í•´ì„œ ì£¼ìš” í¬ì¸íŠ¸ ì¶”ì¶œ
        sentences = re.split(r'[.!?]\s*', content)
        
        # ì¤‘ìš” ë¬¸ì¥ íŒ¨í„´
        important_patterns = [
            r'ì²«ì§¸|ë‘˜ì§¸|ì…‹ì§¸',
            r'ë¨¼ì €|ë‹¤ìŒìœ¼ë¡œ|ë§ˆì§€ë§‰ìœ¼ë¡œ',
            r'íŠ¹íˆ|ì£¼ëª©í• |í•µì‹¬ì€',
            r'ëª©í‘œ|ê³„íš|ì˜ˆì •',
            r'íš¨ê³¼|ê²°ê³¼|ì„±ê³¼',
            r'\d+%|\d+ì–µ|\d+MW'  # ìˆ«ìê°€ í¬í•¨ëœ ë¬¸ì¥
        ]
        
        important_sentences = []
        for sentence in sentences:
            for pattern in important_patterns:
                if re.search(pattern, sentence):
                    important_sentences.append(sentence.strip())
                    break
                    
        # 2. ì¤‘ìš” ë¬¸ì¥ì„ ì†Œì£¼ì œë¡œ ë³€í™˜
        for i, sentence in enumerate(important_sentences[:4]):  # ìµœëŒ€ 4ê°œ
            # ë¬¸ì¥ì„ ê°„ê²°í•˜ê²Œ ìš”ì•½
            if len(sentence) > 50:
                # í•µì‹¬ êµ¬ë¬¸ë§Œ ì¶”ì¶œ
                key_phrase = self._extract_key_phrase(sentence)
            else:
                key_phrase = sentence
                
            sub_theme = {
                'order': i + 1,
                'title': self._create_sub_theme_title(key_phrase),
                'content': key_phrase,
                'type': self._classify_sub_theme(sentence)
            }
            sub_themes.append(sub_theme)
            
        # 3. ì†Œì£¼ì œê°€ ë¶€ì¡±í•˜ë©´ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€
        if len(sub_themes) < 3:
            keywords = self._extract_keywords(content)
            for keyword in keywords:
                if len(sub_themes) >= 4:
                    break
                sub_theme = {
                    'order': len(sub_themes) + 1,
                    'title': keyword,
                    'content': f"{keyword} ê´€ë ¨ ë‚´ìš©",
                    'type': 'keyword'
                }
                sub_themes.append(sub_theme)
                
        return sub_themes
    
    def _extract_key_facts(self, key_points: str) -> List[str]:
        """í•µì‹¬ ì‚¬ì‹¤ ì¶”ì¶œ"""
        
        facts = []
        
        # ê°œì¡°ì‹ ë¬¸ì¥ ë¶„ë¦¬
        lines = key_points.split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('â€¢') or line.startswith('-') or line.startswith('Â·'):
                fact = line[1:].strip()
                if fact:
                    facts.append(fact)
            elif line and len(line) < 100:  # ì§§ì€ ë¬¸ì¥ì€ íŒ©íŠ¸ë¡œ ê°„ì£¼
                facts.append(line)
                
        return facts[:5]  # ìµœëŒ€ 5ê°œ
    
    def _analyze_structure(self, content: str) -> Dict[str, Any]:
        """ì½˜í…ì¸  êµ¬ì¡° ë¶„ì„"""
        
        structure = {
            'has_numbers': bool(re.search(r'\d+', content)),
            'has_quotes': bool(re.search(r'["""''"]', content)),
            'has_future_plan': bool(re.search(r'ì˜ˆì •|ê³„íš|ëª©í‘œ|ì „ë§', content)),
            'has_comparison': bool(re.search(r'ëŒ€ë¹„|ë¹„êµ|ì¦ê°€|ê°ì†Œ|ìƒìŠ¹|í•˜ë½', content)),
            'complexity': 'high' if len(content) > 500 else 'medium' if len(content) > 200 else 'low'
        }
        
        return structure
    
    def _extract_entities(self, content: str) -> Dict[str, List[str]]:
        """ì£¼ìš” ê°œì²´ëª… ì¶”ì¶œ"""
        
        entities = {
            'organizations': [],
            'technologies': [],
            'locations': [],
            'dates': []
        }
        
        # ê¸°ê´€/ê¸°ì—…
        org_pattern = r'([ê°€-í£]+(?:ì „ë ¥|ì—ë„ˆì§€|ê¸°ìˆ |ì‚°ì—…|ê³µì‚¬|ì²­|ë¶€|ì›|ë‹¨|ç¤¾|ì‚¬))'
        entities['organizations'] = list(set(re.findall(org_pattern, content)))[:3]
        
        # ê¸°ìˆ /ì œí’ˆ
        tech_keywords = ['íƒœì–‘ê´‘', 'ESS', 'VPP', 'ë°°í„°ë¦¬', 'ì¸ë²„í„°', 'ìŠ¤ë§ˆíŠ¸ê·¸ë¦¬ë“œ', 'AI', 'IoT']
        for keyword in tech_keywords:
            if keyword in content:
                entities['technologies'].append(keyword)
                
        # ì§€ì—­
        location_pattern = r'([ê°€-í£]+(?:ì‹œ|ë„|êµ¬|êµ°|ì|ë©´|ë™))'
        entities['locations'] = list(set(re.findall(location_pattern, content)))[:3]
        
        # ë‚ ì§œ
        date_pattern = r'(\d{4}ë…„|\d{1,2}ì›”|\d{1,2}ì¼)'
        entities['dates'] = list(set(re.findall(date_pattern, content)))[:3]
        
        return entities
    
    def _extract_numbers(self, content: str) -> List[Dict[str, str]]:
        """í•µì‹¬ ìˆ˜ì¹˜ ì •ë³´ ì¶”ì¶œ"""
        
        numbers = []
        
        # ë‹¤ì–‘í•œ ìˆ«ì íŒ¨í„´
        patterns = [
            (r'(\d+(?:\.\d+)?)\s*MW', 'power', 'MW'),
            (r'(\d+(?:\.\d+)?)\s*kW', 'power', 'kW'),
            (r'(\d+(?:\.\d+)?)\s*%', 'percentage', '%'),
            (r'(\d+(?:,\d{3})*)\s*ì–µ\s*ì›', 'money', 'ì–µì›'),
            (r'(\d+(?:,\d{3})*)\s*ì›', 'money', 'ì›'),
            (r'(\d+)\s*ë…„', 'year', 'ë…„'),
            (r'(\d+)\s*ê°œ', 'count', 'ê°œ'),
            (r'(\d+)\s*ëª…', 'people', 'ëª…')
        ]
        
        for pattern, num_type, unit in patterns:
            matches = re.findall(pattern, content)
            for match in matches:
                # ì£¼ë³€ ë¬¸ë§¥ ì¶”ì¶œ
                context_pattern = rf'[\w\s]{{0,20}}{match}\s*{unit}[\w\s]{{0,20}}'
                context_match = re.search(context_pattern, content)
                if context_match:
                    context = context_match.group().strip()
                else:
                    context = f"{match} {unit}"
                    
                numbers.append({
                    'value': match,
                    'unit': unit,
                    'type': num_type,
                    'context': context
                })
                
        # ì¤‘ë³µ ì œê±° ë° ìƒìœ„ 5ê°œë§Œ ë°˜í™˜
        seen = set()
        unique_numbers = []
        for num in numbers:
            key = f"{num['value']}_{num['unit']}"
            if key not in seen:
                seen.add(key)
                unique_numbers.append(num)
                
        return unique_numbers[:5]
    
    def _categorize_theme(self, title: str) -> str:
        """ì£¼ì œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        
        categories = {
            'ì •ì±…/ê·œì œ': ['ì •ì±…', 'ê·œì œ', 'ë²•ì•ˆ', 'ì œë„', 'ì •ë¶€', 'ì²­', 'ë¶€'],
            'ê¸°ìˆ ê°œë°œ': ['ê°œë°œ', 'ê¸°ìˆ ', 'í˜ì‹ ', 'ì—°êµ¬', 'íŠ¹í—ˆ', 'R&D'],
            'ì‚¬ì—…/íˆ¬ì': ['íˆ¬ì', 'ì‚¬ì—…', 'êµ¬ì¶•', 'ê±´ì„¤', 'ì°©ê³µ', 'ì¤€ê³µ'],
            'ì‹œì¥ë™í–¥': ['ì‹œì¥', 'ê±°ë˜', 'ê°€ê²©', 'ìˆ˜ìš”', 'ê³µê¸‰', 'ì „ë§'],
            'í˜‘ë ¥/ì œíœ´': ['í˜‘ë ¥', 'ì œíœ´', 'MOU', 'í˜‘ì•½', 'íŒŒíŠ¸ë„ˆì‹­'],
            'ì„±ê³¼/ì‹¤ì ': ['ì„±ê³¼', 'ì‹¤ì ', 'ë‹¬ì„±', 'ì¦ê°€', 'ì„±ì¥']
        }
        
        for category, keywords in categories.items():
            for keyword in keywords:
                if keyword in title:
                    return category
                    
        return 'ì¼ë°˜'
    
    def _identify_focus(self, title: str, summary: str) -> str:
        """ì´ˆì  ì‹ë³„"""
        
        combined = f"{title} {summary}".lower()
        
        if any(word in combined for word in ['ë¯¸ë˜', 'ê³„íš', 'ì˜ˆì •', 'ëª©í‘œ']):
            return 'ë¯¸ë˜ì „ë§'
        elif any(word in combined for word in ['ë¬¸ì œ', 'ê³¼ì œ', 'í•´ê²°', 'ëŒ€ì‘']):
            return 'ë¬¸ì œí•´ê²°'
        elif any(word in combined for word in ['ì„±ê³¼', 'ë‹¬ì„±', 'ì™„ë£Œ', 'ì‹¤ì ']):
            return 'ì„±ê³¼ë°œí‘œ'
        elif any(word in combined for word in ['ë„ì…', 'ì‹œì‘', 'ì°©ìˆ˜', 'ê°œì‹œ']):
            return 'ì‹ ê·œë„ì…'
        else:
            return 'í˜„í™©ë³´ê³ '
    
    def _extract_key_phrase(self, sentence: str) -> str:
        """ë¬¸ì¥ì—ì„œ í•µì‹¬ êµ¬ë¬¸ ì¶”ì¶œ"""
        
        # ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ì œê±°
        remove_patterns = [
            r'ì´ì— ë”°ë¼|ë”°ë¼ì„œ|ê·¸ëŸ¬ë‚˜|í•˜ì§€ë§Œ|ë˜í•œ|ì•„ìš¸ëŸ¬',
            r'í•œí¸|íŠ¹íˆ|ì‹¤ì œë¡œ|ì‚¬ì‹¤ìƒ',
            r'ê²ƒìœ¼ë¡œ ì•Œë ¤ì¡Œë‹¤|ê²ƒìœ¼ë¡œ ì „í•´ì¡Œë‹¤|ê³  ë°í˜”ë‹¤|ê³  ì „í–ˆë‹¤'
        ]
        
        result = sentence
        for pattern in remove_patterns:
            result = re.sub(pattern, '', result)
            
        # í•µì‹¬ ë™ì‚¬êµ¬ ì°¾ê¸°
        verb_patterns = [
            r'(\w+ì„?\s*\w+(?:í•œë‹¤|í–ˆë‹¤|í• \s*ì˜ˆì •ì´ë‹¤))',
            r'(\w+(?:ë¥¼|ì„)?\s*\w+í•˜ê¸°ë¡œ\s*í–ˆë‹¤)'
        ]
        
        for pattern in verb_patterns:
            match = re.search(pattern, result)
            if match:
                return match.group().strip()
                
        # íŒ¨í„´ì´ ì—†ìœ¼ë©´ ì• 50ìë§Œ ë°˜í™˜
        return result[:50] + '...' if len(result) > 50 else result
    
    def _create_sub_theme_title(self, phrase: str) -> str:
        """ì†Œì£¼ì œ ì œëª© ìƒì„±"""
        
        # ê¸´ ë¬¸ì¥ì„ ì§§ì€ ì œëª©ìœ¼ë¡œ
        if len(phrase) > 20:
            # í•µì‹¬ ëª…ì‚¬êµ¬ ì¶”ì¶œ
            nouns = re.findall(r'([ê°€-í£]+(?:í™”|ì„±|ë„|ì•ˆ|ì±…|ì—…))', phrase)
            if nouns:
                return nouns[0]
            else:
                return phrase[:15] + '...'
        else:
            return phrase
    
    def _classify_sub_theme(self, sentence: str) -> str:
        """ì†Œì£¼ì œ ìœ í˜• ë¶„ë¥˜"""
        
        if re.search(r'\d+%|\d+ì–µ|\d+MW', sentence):
            return 'data'
        elif re.search(r'ëª©í‘œ|ê³„íš|ì˜ˆì •', sentence):
            return 'plan'
        elif re.search(r'íš¨ê³¼|ê¸°ëŒ€|ì „ë§', sentence):
            return 'effect'
        elif re.search(r'ë¬¸ì œ|ê³¼ì œ|ì–´ë ¤ì›€', sentence):
            return 'challenge'
        else:
            return 'fact'
    
    def _extract_keywords(self, content: str) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        
        # ë‹¨ì–´ ë¹ˆë„ ë¶„ì„
        words = re.findall(r'[ê°€-í£]{2,}', content)
        word_freq = Counter(words)
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = ['ìˆë‹¤', 'ì—†ë‹¤', 'í•˜ë‹¤', 'ë˜ë‹¤', 'ì´ë‹¤', 'ê·¸ë¦¬ê³ ', 'ë˜í•œ', 'í•˜ì§€ë§Œ']
        for stopword in stopwords:
            word_freq.pop(stopword, None)
            
        # ìƒìœ„ í‚¤ì›Œë“œ ë°˜í™˜
        return [word for word, count in word_freq.most_common(5)]


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    analyzer = ArticleContentAnalyzer()
    
    # ìƒ˜í”Œ ê¸°ì‚¬
    sample = {
        'title': 'í•œì „, ì œì£¼ ì¬ìƒì—ë„ˆì§€ ì¶œë ¥ì œì–´ í•´ê²° ìœ„í•œ ESS 300MW êµ¬ì¶• ì¶”ì§„',
        'summary': 'í•œêµ­ì „ë ¥ê³µì‚¬ê°€ ì œì£¼ë„ì˜ ì¬ìƒì—ë„ˆì§€ ì¶œë ¥ì œì–´ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ 300MW ê·œëª¨ì˜ ESSë¥¼ êµ¬ì¶•í•œë‹¤ê³  ë°œí‘œí–ˆë‹¤.',
        'key_points': 'â€¢ 2026ë…„ê¹Œì§€ 300MW ESS êµ¬ì¶•\nâ€¢ ì´ ì‚¬ì—…ë¹„ 5000ì–µì› íˆ¬ì…\nâ€¢ ì¶œë ¥ì œì–´ìœ¨ 30%ì—ì„œ 10%ë¡œ ê°ì†Œ ê¸°ëŒ€\nâ€¢ ì§€ì—­ ì£¼ë¯¼ ì¼ìë¦¬ 500ê°œ ì°½ì¶œ',
        'source': 'ì „ê¸°ì‹ ë¬¸'
    }
    
    analysis = analyzer.analyze_article(sample)
    
    print("ğŸ“Š ê¸°ì‚¬ ë¶„ì„ ê²°ê³¼")
    print("=" * 50)
    print(f"\nğŸ¯ ëŒ€ì£¼ì œ: {analysis['main_theme']['theme']}")
    print(f"   ì¹´í…Œê³ ë¦¬: {analysis['main_theme']['category']}")
    print(f"   ì´ˆì : {analysis['main_theme']['focus']}")
    
    print("\nğŸ“Œ ì†Œì£¼ì œ:")
    for sub in analysis['sub_themes']:
        print(f"   {sub['order']}. {sub['title']} ({sub['type']})")
        
    print("\nğŸ’¡ í•µì‹¬ ì‚¬ì‹¤:")
    for fact in analysis['key_facts']:
        print(f"   â€¢ {fact}")
        
    print("\nğŸ”¢ ì£¼ìš” ìˆ˜ì¹˜:")
    for num in analysis['numbers']:
        print(f"   â€¢ {num['value']} {num['unit']}: {num['context']}")
