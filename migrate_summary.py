#!/usr/bin/env python3
"""
ìš”ì•½ HTMLì„ JSON í˜•ì‹ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""
import json
import re
from pathlib import Path
from datetime import datetime
from bs4 import BeautifulSoup
from card_news_paths import get_path_str
import argparse

class SummaryMigrator:
    def __init__(self):
        self.html_path = Path("output/card_news/summary/improved_summary.html")
        self.json_path = Path(get_path_str('summary_json'))
        
    def parse_html(self):
        """HTML íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ì¹´ë“œ ì •ë³´ ì¶”ì¶œ"""
        if not self.html_path.exists():
            print(f"âŒ HTML íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.html_path}")
            return None
            
        with open(self.html_path, 'r', encoding='utf-8') as f:
            html_content = f.read()
            
        soup = BeautifulSoup(html_content, 'html.parser')
        cards = []
        
        # ëª¨ë“  news-card ì°¾ê¸°
        for card_div in soup.find_all('div', class_='news-card'):
            try:
                # onclick ì†ì„±ì—ì„œ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
                onclick = card_div.get('onclick', '')
                file_match = re.search(r"'([^']+\.html)'", onclick)
                file_path = file_match.group(1) if file_match else ''
                
                # ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
                category_span = card_div.find('span', class_='card-category')
                category = category_span.text.strip() if category_span else ''
                
                # ì œëª© ì¶”ì¶œ
                title_h3 = card_div.find('h3', class_='card-title')
                title = title_h3.text.strip() if title_h3 else ''
                
                # ìš”ì•½ ì¶”ì¶œ
                summary_p = card_div.find('p', class_='card-summary')
                summary = summary_p.text.strip() if summary_p else ''
                
                # ë‚ ì§œ ì¶”ì¶œ
                date_span = card_div.find('span', class_='card-date')
                date = date_span.text.strip() if date_span else ''
                
                # íŒŒì¼ëª…ì—ì„œ ID ìƒì„±
                file_name = Path(file_path).name if file_path else ''
                card_id = file_name.replace('.html', '') if file_name else f"card_{len(cards)}"
                
                # í‚¤ì›Œë“œ ì¶”ì¶œ (ì¹´í…Œê³ ë¦¬ ê¸°ë°˜)
                keywords = self._extract_keywords(category, title)
                
                card_data = {
                    "id": card_id,
                    "title": title,
                    "summary": summary,
                    "keywords": keywords,
                    "date": date,
                    "file_path": file_path.replace('../html/', ''),  # ìƒëŒ€ ê²½ë¡œ ì •ë¦¬
                    "category": category,
                    "added_date": datetime.now().isoformat()
                }
                
                cards.append(card_data)
                
            except Exception as e:
                print(f"âš ï¸ ì¹´ë“œ íŒŒì‹± ì˜¤ë¥˜: {e}")
                continue
                
        return {"cards": cards}
    
    def _extract_keywords(self, category, title):
        """ì¹´í…Œê³ ë¦¬ì™€ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = []
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
        category_keywords = {
            "ESS": ["ESS", "ì—ë„ˆì§€ì €ì¥"],
            "VPP": ["VPP", "ê°€ìƒë°œì „ì†Œ"],
            "ì¬ìƒì—ë„ˆì§€": ["ì¬ìƒì—ë„ˆì§€", "ì‹ ì¬ìƒ"],
            "íƒœì–‘ê´‘": ["íƒœì–‘ê´‘", "ì†”ë¼"],
            "í’ë ¥": ["í’ë ¥", "í•´ìƒí’ë ¥"],
            "ì „ë ¥ì‹œì¥": ["ì „ë ¥ì‹œì¥", "ì „ë ¥ê±°ë˜"],
            "ì •ì±…": ["ì •ì±…", "ì •ë¶€"],
            "íˆ¬ì": ["íˆ¬ì", "ê¸ˆìœµ"]
        }
        
        # ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í‚¤ì›Œë“œ
        for cat, kws in category_keywords.items():
            if cat in category:
                keywords.extend(kws)
                break
        
        # ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        keyword_patterns = ["ESS", "VPP", "íƒœì–‘ê´‘", "í’ë ¥", "ì¬ìƒì—ë„ˆì§€", "ì „ë ¥", "ì—ë„ˆì§€", "ë°°í„°ë¦¬"]
        for pattern in keyword_patterns:
            if pattern in title and pattern not in keywords:
                keywords.append(pattern)
        
        return keywords[:5]  # ìµœëŒ€ 5ê°œ
    
    def save_json(self, data, dry_run=False):
        """JSON íŒŒì¼ë¡œ ì €ì¥"""
        if dry_run:
            print("\nğŸ” [DRY RUN] JSON ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:")
            print(json.dumps(data, ensure_ascii=False, indent=2)[:1000])
            print(f"\nì´ {len(data['cards'])}ê°œì˜ ì¹´ë“œê°€ ë§ˆì´ê·¸ë ˆì´ì…˜ë  ì˜ˆì •ì…ë‹ˆë‹¤.")
            return True
            
        try:
            # ë””ë ‰í† ë¦¬ í™•ì¸
            self.json_path.parent.mkdir(parents=True, exist_ok=True)
            
            # JSON ì €ì¥
            with open(self.json_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
                
            print(f"âœ… JSON íŒŒì¼ ì €ì¥ ì™„ë£Œ: {self.json_path}")
            print(f"   ì´ {len(data['cards'])}ê°œì˜ ì¹´ë“œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
            return True
            
        except Exception as e:
            print(f"âŒ JSON ì €ì¥ ì‹¤íŒ¨: {e}")
            return False
    
    def migrate(self, dry_run=False):
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        print("ğŸš€ ìš”ì•½ í˜ì´ì§€ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘...")
        
        # HTML íŒŒì‹±
        data = self.parse_html()
        if not data:
            return False
        
        # JSON ì €ì¥
        return self.save_json(data, dry_run)

def main():
    parser = argparse.ArgumentParser(description='ìš”ì•½ HTMLì„ JSONìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜')
    parser.add_argument('--dry-run', action='store_true', help='ì‹¤ì œ ì €ì¥í•˜ì§€ ì•Šê³  ë¯¸ë¦¬ë³´ê¸°ë§Œ')
    args = parser.parse_args()
    
    migrator = SummaryMigrator()
    success = migrator.migrate(dry_run=args.dry_run)
    
    if success and not args.dry_run:
        print("\nâœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
        print("ë‹¤ìŒ ë‹¨ê³„: update_summary.pyë¥¼ ìˆ˜ì •í•˜ì—¬ JSONë„ ì—…ë°ì´íŠ¸í•˜ë„ë¡ ë³€ê²½")

if __name__ == "__main__":
    main()
