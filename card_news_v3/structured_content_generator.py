#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“ êµ¬ì¡°í™”ëœ ì½˜í…ì¸  ìƒì„±ê¸°
- í•µì‹¬ ì£¼ì œ ì¶”ì¶œ
- ì†Œì£¼ì œ ë¶„ë¥˜
- ë°ì´í„° ì‹œê°í™” ìš”ì†Œ ì¶”ì¶œ
"""

import os
import re
import json
import requests
from typing import Dict, List, Any

class StructuredContentGenerator:
    def __init__(self):
        # Ollama ì„¤ì •
        self.ollama_url = os.getenv('OLLAMA_API_URL', 'http://localhost:11434/v1/chat/completions')
        self.model = os.getenv('OLLAMA_MODEL', 'mistral:7b-instruct-v0.2-q5_k_m')
        
    def generate_structured_summary(self, article_content: str) -> Dict[str, Any]:
        """êµ¬ì¡°í™”ëœ ìš”ì•½ ìƒì„±"""
        
        # í”„ë¡¬í”„íŠ¸ ì„¤ê³„
        prompt = f"""ë‹¤ìŒ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ìš”ì•½ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ê¸°ì‚¬ ë‚´ìš©:
{article_content[:2000]}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

1. í•µì‹¬ ì£¼ì œ: (í•œ ë¬¸ì¥ìœ¼ë¡œ í•µì‹¬ ë©”ì‹œì§€)

2. ì£¼ìš” í¬ì¸íŠ¸:
- í¬ì¸íŠ¸1: (êµ¬ì²´ì ì¸ ë‚´ìš©)
- í¬ì¸íŠ¸2: (êµ¬ì²´ì ì¸ ë‚´ìš©)
- í¬ì¸íŠ¸3: (êµ¬ì²´ì ì¸ ë‚´ìš©)

3. í•µì‹¬ ë°ì´í„°:
- ìˆ˜ì¹˜1: (êµ¬ì²´ì ì¸ ìˆ«ìì™€ ì˜ë¯¸)
- ìˆ˜ì¹˜2: (êµ¬ì²´ì ì¸ ìˆ«ìì™€ ì˜ë¯¸)

4. ì‹œì‚¬ì : (ì´ ê¸°ì‚¬ê°€ ì „ë ¥ì‚°ì—…ì— ë¯¸ì¹˜ëŠ” ì˜í–¥)
"""
        
        try:
            # Ollama API í˜¸ì¶œ
            response = requests.post(
                self.ollama_url,
                json={
                    "model": self.model,
                    "messages": [
                        {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë ¥ì‚°ì—… ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ê¸°ì‚¬ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í•µì‹¬ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”."},
                        {"role": "user", "content": prompt}
                    ],
                    "stream": False
                },
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                content = result.get('choices', [{}])[0].get('message', {}).get('content', '')
                
                # êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ íŒŒì‹±
                return self._parse_structured_content(content)
            else:
                print(f"Ollama API ì˜¤ë¥˜: {response.status_code}")
                return self._fallback_summary(article_content)
                
        except Exception as e:
            print(f"ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return self._fallback_summary(article_content)
            
    def _parse_structured_content(self, content: str) -> Dict[str, Any]:
        """ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ íŒŒì‹±"""
        structured = {
            'core_topic': '',
            'main_points': [],
            'key_data': [],
            'implications': ''
        }
        
        lines = content.split('\n')
        current_section = None
        
        for line in lines:
            line = line.strip()
            
            if 'í•µì‹¬ ì£¼ì œ:' in line:
                structured['core_topic'] = line.split('í•µì‹¬ ì£¼ì œ:')[-1].strip()
            elif 'ì£¼ìš” í¬ì¸íŠ¸:' in line:
                current_section = 'points'
            elif 'í•µì‹¬ ë°ì´í„°:' in line:
                current_section = 'data'
            elif 'ì‹œì‚¬ì :' in line:
                current_section = 'implications'
            elif line.startswith('-') and current_section:
                content = line[1:].strip()
                if current_section == 'points':
                    structured['main_points'].append(content)
                elif current_section == 'data':
                    structured['key_data'].append(content)
            elif current_section == 'implications' and line:
                structured['implications'] += line + ' '
                
        return structured
        
    def _fallback_summary(self, content: str) -> Dict[str, Any]:
        """ê·œì¹™ ê¸°ë°˜ í´ë°± ìš”ì•½"""
        sentences = re.split(r'[.!?]', content)
        sentences = [s.strip() for s in sentences if s.strip()]
        
        return {
            'core_topic': sentences[0] if sentences else 'ë‚´ìš© ì—†ìŒ',
            'main_points': sentences[1:4] if len(sentences) > 1 else [],
            'key_data': self._extract_numbers(content),
            'implications': 'ì¶”ê°€ ë¶„ì„ í•„ìš”'
        }
        
    def _extract_numbers(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ë°ì´í„° ì¶”ì¶œ"""
        # ìˆ«ìì™€ ë‹¨ìœ„ê°€ í¬í•¨ëœ íŒ¨í„´ ì°¾ê¸°
        patterns = [
            r'\d+(?:\.\d+)?%',  # í¼ì„¼íŠ¸
            r'\d+(?:,\d{3})*(?:\.\d+)?(?:ì›|ë‹¬ëŸ¬|MW|GW|kWh)',  # ë‹¨ìœ„ í¬í•¨
            r'\d{4}ë…„',  # ì—°ë„
        ]
        
        results = []
        for pattern in patterns:
            matches = re.findall(pattern, text)
            results.extend(matches)
            
        return results[:5]  # ìµœëŒ€ 5ê°œê¹Œì§€
        
    def extract_visualization_data(self, articles: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ì‹œê°í™”ë¥¼ ìœ„í•œ ë°ì´í„° ì¶”ì¶œ"""
        viz_data = {
            'timeline': [],  # ì‹œê°„ëŒ€ë³„ ë°ì´í„°
            'categories': {},  # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
            'trends': [],  # íŠ¸ë Œë“œ ë°ì´í„°
            'comparisons': []  # ë¹„êµ ë°ì´í„°
        }
        
        # ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜
        for article in articles:
            for keyword in article.get('keywords', []):
                viz_data['categories'][keyword] = viz_data['categories'].get(keyword, 0) + 1
                
        # ë‚ ì§œë³„ ë¶„ë¥˜
        date_counts = {}
        for article in articles:
            if article.get('published_date'):
                date_str = str(article['published_date'])[:10]
                date_counts[date_str] = date_counts.get(date_str, 0) + 1
                
        viz_data['timeline'] = [
            {'date': date, 'count': count} 
            for date, count in sorted(date_counts.items())
        ]
        
        # AI ì¶”ì²œ vs ì¼ë°˜
        ai_count = sum(1 for a in articles if a.get('ai_recommend'))
        viz_data['comparisons'] = [
            {'label': 'AI ì¶”ì²œ', 'value': ai_count},
            {'label': 'ì¼ë°˜', 'value': len(articles) - ai_count}
        ]
        
        return viz_data

# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    generator = StructuredContentGenerator()
    
    # í…ŒìŠ¤íŠ¸ ê¸°ì‚¬
    test_content = """
    í•œêµ­ì—ë„ˆì§€ê¸°ìˆ ì—°êµ¬ì›ì€ ì°¨ì„¸ëŒ€ í˜ë¡œë¸ŒìŠ¤ì¹´ì´íŠ¸ íƒœì–‘ì „ì§€ ê¸°ìˆ ì„ ê°œë°œí•´ 
    ì—ë„ˆì§€ ë³€í™˜ íš¨ìœ¨ 30%ë¥¼ ë‹¬ì„±í–ˆë‹¤ê³  ë°œí‘œí–ˆë‹¤. ì´ëŠ” ê¸°ì¡´ ì‹¤ë¦¬ì½˜ íƒœì–‘ì „ì§€ 
    ëŒ€ë¹„ 50% ì´ìƒ ì œì¡°ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆìœ¼ë©°, 2025ë…„ ìƒìš©í™”ë¥¼ ëª©í‘œë¡œ í•˜ê³  ìˆë‹¤.
    
    ì—°êµ¬íŒ€ì€ ìƒˆë¡œìš´ ì†Œì¬ ì¡°í•©ê³¼ ì œì¡° ê³µì • ìµœì í™”ë¥¼ í†µí•´ ì•ˆì •ì„±ê³¼ íš¨ìœ¨ì„±ì„ 
    ë™ì‹œì— í™•ë³´í–ˆë‹¤. íŠ¹íˆ ê³ ì˜¨ ë‹¤ìŠµí•œ í™˜ê²½ì—ì„œë„ 90% ì´ìƒì˜ íš¨ìœ¨ì„ ìœ ì§€í•  ìˆ˜ 
    ìˆì–´ ì‹¤ì œ í™˜ê²½ì—ì„œì˜ ì ìš© ê°€ëŠ¥ì„±ì„ ì…ì¦í–ˆë‹¤.
    """
    
    # êµ¬ì¡°í™”ëœ ìš”ì•½ ìƒì„±
    summary = generator.generate_structured_summary(test_content)
    print("êµ¬ì¡°í™”ëœ ìš”ì•½:")
    print(json.dumps(summary, ensure_ascii=False, indent=2))
