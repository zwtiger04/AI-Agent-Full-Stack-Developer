#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ“Š êµ¬ì¡°í™”ëœ ì½˜í…ì¸  ìƒì„±ê¸°
- ë…¸ì…˜ ë°ì´í„°ë¥¼ êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ë¶„ì„
- ì¹´ë“œ ë‰´ìŠ¤ìš© í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
"""

from typing import Dict, List, Any
from datetime import datetime
import pandas as pd
from collections import Counter
import re

class StructuredContentGenerator:
    """êµ¬ì¡°í™”ëœ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.category_keywords = {
            'íƒœì–‘ê´‘': ['íƒœì–‘ê´‘', 'íƒœì–‘ì „ì§€', 'PV', 'ëª¨ë“ˆ'],
            'ESS': ['ESS', 'ì—ë„ˆì§€ì €ì¥', 'ë°°í„°ë¦¬', 'BESS'],
            'ì „ë ¥ë§': ['ì „ë ¥ë§', 'ì†¡ì „', 'ë°°ì „', 'ê³„í†µ'],
            'ì¬ìƒì—ë„ˆì§€': ['ì¬ìƒì—ë„ˆì§€', 'ì‹ ì¬ìƒ', 'RE100', 'íƒ„ì†Œì¤‘ë¦½'],
            'VPP': ['VPP', 'ê°€ìƒë°œì „ì†Œ', 'ë¶„ì‚°ìì›', 'DR'],
            'ì •ì±…': ['ì •ì±…', 'ë²•ì•ˆ', 'ê·œì œ', 'ì •ë¶€', 'ì „ë ¥ê°ë…ì›'],
            'ì‹œì¥': ['ì „ë ¥ì‹œì¥', 'ì „ë ¥ê±°ë˜', 'SMP', 'REC']
        }
        
    def analyze_articles(self, articles: List[Dict]) -> Dict[str, Any]:
        """ê¸°ì‚¬ ëª©ë¡ì„ ë¶„ì„í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„±
        
        Args:
            articles: ë…¸ì…˜ì—ì„œ ê°€ì ¸ì˜¨ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            êµ¬ì¡°í™”ëœ ë¶„ì„ ê²°ê³¼
        """
        
        analysis = {
            'summary': self._generate_summary(articles),
            'categories': self._analyze_categories(articles),
            'trends': self._extract_trends(articles),
            'key_insights': self._extract_key_insights(articles),
            'statistics': self._calculate_statistics(articles),
            'top_articles': self._select_top_articles(articles)
        }
        
        return analysis
    
    def _generate_summary(self, articles: List[Dict]) -> Dict[str, Any]:
        """ì „ì²´ ìš”ì•½ ì •ë³´ ìƒì„±"""
        return {
            'total_articles': len(articles),
            'period': self._get_period(articles),
            'main_theme': self._extract_main_theme(articles)
        }
    
    def _analyze_categories(self, articles: List[Dict]) -> Dict[str, int]:
        """ì¹´í…Œê³ ë¦¬ë³„ ê¸°ì‚¬ ë¶„ë¥˜"""
        category_count = Counter()
        
        for article in articles:
            # ì œëª©ê³¼ í•œì¤„ìš”ì•½ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            text = f"{article.get('title', '')} {article.get('summary', '')}"
            categories = self._extract_categories(text)
            
            for category in categories:
                category_count[category] += 1
                
        return dict(category_count.most_common())
    
    def _extract_categories(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ"""
        found_categories = []
        
        for category, keywords in self.category_keywords.items():
            for keyword in keywords:
                if keyword.lower() in text.lower():
                    found_categories.append(category)
                    break
                    
        return found_categories if found_categories else ['ê¸°íƒ€']
    
    def _extract_trends(self, articles: List[Dict]) -> List[Dict[str, str]]:
        """ì£¼ìš” íŠ¸ë Œë“œ ì¶”ì¶œ"""
        trends = []
        
        # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
        keyword_counter = Counter()
        for article in articles:
            keywords = article.get('keywords', [])
            keyword_counter.update(keywords)
        
        # ìƒìœ„ 5ê°œ íŠ¸ë Œë“œ
        for keyword, count in keyword_counter.most_common(5):
            trend = {
                'keyword': keyword,
                'count': count,
                'description': f"{keyword} ê´€ë ¨ ì´ìŠˆê°€ {count}ê±´ ë³´ë„ë¨"
            }
            trends.append(trend)
            
        return trends
    
    def _extract_key_insights(self, articles: List[Dict]) -> List[str]:
        """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ"""
        insights = []
        
        # AI ì¶”ì²œ ê¸°ì‚¬ ìš°ì„ 
        ai_recommended = [a for a in articles if a.get('ai_recommend', False)]
        
        if ai_recommended:
            insights.append(f"ğŸ¤– AIê°€ ì£¼ëª©í•œ ê¸°ì‚¬ {len(ai_recommended)}ê±´")
            
        # ê´€ì‹¬ í‘œì‹œëœ ê¸°ì‚¬
        interested = [a for a in articles if a.get('interest', False)]
        if interested:
            insights.append(f"â­ ì‚¬ìš©ì ê´€ì‹¬ ê¸°ì‚¬ {len(interested)}ê±´")
            
        # ì¹´í…Œê³ ë¦¬ë³„ íŠ¹ì§•
        categories = self._analyze_categories(articles)
        if categories:
            top_category = list(categories.keys())[0]
            insights.append(f"ğŸ“Š {top_category} ë¶„ì•¼ê°€ ê°€ì¥ í™œë°œ ({categories[top_category]}ê±´)")
            
        return insights[:5]  # ìµœëŒ€ 5ê°œ
    
    def _calculate_statistics(self, articles: List[Dict]) -> Dict[str, Any]:
        """í†µê³„ ì •ë³´ ê³„ì‚°"""
        return {
            'total': len(articles),
            'ai_recommended': len([a for a in articles if a.get('ai_recommend', False)]),
            'user_interested': len([a for a in articles if a.get('interest', False)]),
            'avg_keywords': sum(len(a.get('keywords', [])) for a in articles) / max(len(articles), 1)
        }
    
    def _select_top_articles(self, articles: List[Dict], count: int = 3) -> List[Dict]:
        """ì£¼ìš” ê¸°ì‚¬ ì„ ì •"""
        # ìš°ì„ ìˆœìœ„: 1) ì‚¬ìš©ì ê´€ì‹¬ 2) AI ì¶”ì²œ 3) ìµœì‹ 
        
        # ê´€ì‹¬ í‘œì‹œëœ ê¸°ì‚¬
        interested = [a for a in articles if a.get('interest', False)]
        
        # AI ì¶”ì²œ ê¸°ì‚¬
        ai_recommended = [a for a in articles if a.get('ai_recommend', False) and not a.get('interest', False)]
        
        # ë‚˜ë¨¸ì§€ ê¸°ì‚¬ (ë‚ ì§œìˆœ)
        others = [a for a in articles if not a.get('interest', False) and not a.get('ai_recommend', False)]
        
        # í•©ì¹˜ê¸°
        top_articles = (interested + ai_recommended + others)[:count]
        
        return top_articles
    
    def _get_period(self, articles: List[Dict]) -> str:
        """ê¸°ì‚¬ ê¸°ê°„ ì¶”ì¶œ"""
        if not articles:
            return "ë°ì´í„° ì—†ìŒ"
            
        # ë‚ ì§œ íŒŒì‹± ì‹œë„
        dates = []
        for article in articles:
            date_str = article.get('published_date')
            if date_str:
                try:
                    # ISO í˜•ì‹ ë‚ ì§œ íŒŒì‹±
                    if 'T' in str(date_str):
                        date = datetime.fromisoformat(str(date_str).replace('Z', '+00:00'))
                    else:
                        date = datetime.strptime(str(date_str), '%Y-%m-%d')
                    dates.append(date)
                except:
                    pass
                    
        if not dates:
            return datetime.now().strftime("%Yë…„ %mì›”")
            
        min_date = min(dates)
        max_date = max(dates)
        
        if min_date.date() == max_date.date():
            return min_date.strftime("%Yë…„ %mì›” %dì¼")
        else:
            return f"{min_date.strftime('%m/%d')} ~ {max_date.strftime('%m/%d')}"
    
    def _extract_main_theme(self, articles: List[Dict]) -> str:
        """ì£¼ìš” í…Œë§ˆ ì¶”ì¶œ"""
        if not articles:
            return "ì „ë ¥ì‚°ì—… ë™í–¥"
            
        # ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ í‚¤ì›Œë“œ
        keyword_counter = Counter()
        for article in articles:
            keywords = article.get('keywords', [])
            keyword_counter.update(keywords)
            
        if keyword_counter:
            main_keyword = keyword_counter.most_common(1)[0][0]
            return f"{main_keyword} ì¤‘ì‹¬ì˜ ì „ë ¥ì‚°ì—… ë™í–¥"
        else:
            return "ì „ë ¥ì‚°ì—… ì¢…í•© ë™í–¥"


# í…ŒìŠ¤íŠ¸ìš© ë©”ì¸ í•¨ìˆ˜
if __name__ == "__main__":
    # ì˜ˆì‹œ ë°ì´í„°
    sample_articles = [
        {
            'title': 'íƒœì–‘ê´‘ ë°œì „ íš¨ìœ¨ 20% í–¥ìƒ',
            'summary': 'ìƒˆë¡œìš´ ê¸°ìˆ ë¡œ íƒœì–‘ê´‘ íŒ¨ë„ íš¨ìœ¨ì„± ëŒ€í­ ê°œì„ ',
            'keywords': ['íƒœì–‘ê´‘', 'íš¨ìœ¨ì„±', 'ì‹ ê¸°ìˆ '],
            'ai_recommend': True,
            'interest': False
        },
        {
            'title': 'ESS í™”ì¬ ì•ˆì „ ê¸°ì¤€ ê°•í™”',
            'summary': 'ì •ë¶€, ESS ì„¤ì¹˜ ë° ìš´ì˜ ì•ˆì „ ê·œì • ê°œì •',
            'keywords': ['ESS', 'ì•ˆì „', 'ì •ì±…'],
            'ai_recommend': False,
            'interest': True
        }
    ]
    
    generator = StructuredContentGenerator()
    analysis = generator.analyze_articles(sample_articles)
    
    print("ğŸ“Š êµ¬ì¡°í™”ëœ ì½˜í…ì¸  ë¶„ì„ ê²°ê³¼:")
    print(f"ìš”ì•½: {analysis['summary']}")
    print(f"ì¹´í…Œê³ ë¦¬: {analysis['categories']}")
    print(f"íŠ¸ë Œë“œ: {analysis['trends']}")
    print(f"ì¸ì‚¬ì´íŠ¸: {analysis['key_insights']}")
