# ê°œì„ ëœ AI ì½˜í…ì¸  ì—…ë°ì´íŠ¸ ëª¨ë“ˆ
import time
import re
import traceback
import requests
import os
from dotenv import load_dotenv
from googletrans import Translator

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Ollama API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
OLLAMA_API_URL = os.getenv('OLLAMA_API_URL', 'http://localhost:11434/v1/chat/completions')
OLLAMA_MODEL = os.getenv('OLLAMA_MODEL', 'gemma2:9b-instruct-q5_K_M')

# googletrans-py Translator ê°ì²´ ì´ˆê¸°í™”
translator = Translator()

def clean_article_content(content: str) -> str:
    """ê¸°ì‚¬ ë‚´ìš©ì„ ì •ì œí•©ë‹ˆë‹¤."""
    if not content:
        return ""
    
    # 1. ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
    content = ' '.join(content.split())
    
    # 2. íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
    content = content.replace('&nbsp;', ' ')
    
    # 3. ì¤‘ë³µëœ ë§ˆì¹¨í‘œ ì œê±°
    content = content.replace('..', '.')
    
    return content

def extract_key_sentences(content: str, max_sentences: int = 10) -> list:
    """
    ğŸ” ê¸°ì‚¬ì—ì„œ ì¤‘ìš”í•œ ë¬¸ì¥ë“¤ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    - ìˆ«ìê°€ í¬í•¨ëœ ë¬¸ì¥ ìš°ì„ 
    - ì¸ìš©ë¬¸ì´ í¬í•¨ëœ ë¬¸ì¥
    - í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥
    """
    if not content:
        return []
    
    # ì „ë ¥ì‚°ì—… ê´€ë ¨ ì¤‘ìš” í‚¤ì›Œë“œ
    IMPORTANT_KEYWORDS = [
        'ì¬ìƒì—ë„ˆì§€', 'VPP', 'ESS', 'íƒœì–‘ê´‘', 'í’ë ¥', 
        'ì „ë ¥', 'MW', 'GW', 'ì—ë„ˆì§€', 'íƒ„ì†Œ', 
        'ì •ì±…', 'íˆ¬ì', 'ì‚¬ì—…', 'ê³„íš', 'ì¶”ì§„'
    ]
    
    # ë¬¸ì¥ ë¶„ë¦¬
    sentences = re.split(r'[.!?]\s+', content)
    sentences = [s.strip() for s in sentences if len(s.strip()) > 20]
    
    # ë¬¸ì¥ ì ìˆ˜ ê³„ì‚°
    scored_sentences = []
    for sent in sentences:
        score = 0
        
        # ìˆ«ì í¬í•¨ ì‹œ ê°€ì¤‘ì¹˜
        if re.search(r'\d+', sent):
            score += 3
        
        # ì¸ìš©ë¬¸ í¬í•¨ ì‹œ ê°€ì¤‘ì¹˜
        if '"' in sent or 'â€³' in sent:
            score += 2
        
        # ì¤‘ìš” í‚¤ì›Œë“œ í¬í•¨ ì‹œ ê°€ì¤‘ì¹˜
        for keyword in IMPORTANT_KEYWORDS:
            if keyword in sent:
                score += 2
                
        # ë¬¸ì¥ ê¸¸ì´ ê°€ì¤‘ì¹˜ (ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ë¬¸ì¥ íŒ¨ë„í‹°)
        if 50 <= len(sent) <= 200:
            score += 1
            
        scored_sentences.append((score, sent))
    
    # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    scored_sentences.sort(key=lambda x: x[0], reverse=True)
    
    # ìƒìœ„ ë¬¸ì¥ë“¤ ë°˜í™˜
    return [sent for _, sent in scored_sentences[:max_sentences]]

def generate_enhanced_summary(content: str, use_llm: bool = True) -> str:
    """
    ğŸš€ ê°œì„ ëœ í•œì¤„ ìš”ì•½ ìƒì„±
    - ë” êµ¬ì²´ì ì¸ í”„ë¡¬í”„íŠ¸
    - ì¤‘ìš” ë¬¸ì¥ ìš°ì„  ì „ë‹¬
    - í›„ì²˜ë¦¬ ê°•í™”
    """
    if not use_llm or not content:
        return generate_one_line_summary_rule_based(content)
    
    try:
        # ì¤‘ìš” ë¬¸ì¥ ì¶”ì¶œ
        key_sentences = extract_key_sentences(content, max_sentences=5)
        key_content = ' '.join(key_sentences) if key_sentences else content[:1000]
        
        # ê°œì„ ëœ í”„ë¡¬í”„íŠ¸
        korean_prompt = f"""ë‹¹ì‹ ì€ ì „ë ¥ì‚°ì—… ì „ë¬¸ ê¸°ìì…ë‹ˆë‹¤. ë‹¤ìŒ ê¸°ì‚¬ì˜ í•µì‹¬ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”.

ìš”ì•½ ê·œì¹™:
1. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
2. ê°€ì¥ ì¤‘ìš”í•œ ì •ë³´ í¬í•¨ (ëˆ„ê°€, ë¬´ì—‡ì„, ì™œ)
3. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë‚˜ ê·œëª¨ í¬í•¨
4. 100-150ì ì´ë‚´
5. "~ë‹¤", "~í–ˆë‹¤"ë¡œ ëë‚˜ëŠ” ì™„ì „í•œ ë¬¸ì¥

ê¸°ì‚¬ í•µì‹¬ ë‚´ìš©:
{key_content}

í•œì¤„ ìš”ì•½:"""

        response = requests.post(
            OLLAMA_API_URL,
            json={
                "model": OLLAMA_MODEL,
                "messages": [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì˜ ì „ë ¥ì‚°ì—… ì „ë¬¸ ê¸°ìì…ë‹ˆë‹¤. ì˜¤ì§ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."},
                    {"role": "user", "content": korean_prompt}
                ],
                "temperature": 0.3,  # ë” ì¼ê´€ëœ ê²°ê³¼ë¥¼ ìœ„í•´ ë‚®ì€ ì˜¨ë„
                "stream": False
            },
            timeout=60
        )

        if response.status_code == 200:
            result = response.json()
            summary = result.get('choices', [{}])[0].get('message', {}).get('content', '').strip()
            
            # í›„ì²˜ë¦¬: ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
            summary = summary.replace('í•œì¤„ ìš”ì•½:', '').replace('ìš”ì•½:', '').strip()
            summary = re.sub(r'^[-â€¢*]\s*', '', summary)  # ë¶ˆë¦¿ í¬ì¸íŠ¸ ì œê±°
            
            # ê¸¸ì´ ì¡°ì •
            if len(summary) > 150:
                summary = summary[:147] + '...'
                
            return summary
            
    except Exception as e:
        print(f"[Enhanced Summary] ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return generate_one_line_summary_rule_based(content)

def generate_detailed_key_content(content: str, use_llm: bool = True) -> str:
    """
    ğŸ“Š ìƒì„¸í•˜ê³  êµ¬ì¡°í™”ëœ í•µì‹¬ ë‚´ìš© ìƒì„±
    - ì¹´í…Œê³ ë¦¬ë³„ ì •ë¦¬
    - ë” ë§ì€ ì •ë³´ í¬í•¨
    - ì½ê¸° ì‰¬ìš´ êµ¬ì¡°
    """
    if not use_llm or not content:
        return generate_key_content_rule_based(content)
    
    try:
        # ì „ì²´ ë‚´ìš© ì‚¬ìš© (2000ìê¹Œì§€)
        full_content = content[:2000]
        
        # êµ¬ì¡°í™”ëœ í”„ë¡¬í”„íŠ¸
        korean_prompt = f"""ë‹¹ì‹ ì€ ì „ë ¥ì‚°ì—… ì „ë¬¸ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ê¸°ì‚¬ë¥¼ ë¶„ì„í•˜ì—¬ í•µì‹¬ ë‚´ìš©ì„ ì •ë¦¬í•˜ì„¸ìš”.

ë¶„ì„ í˜•ì‹:
ğŸ“Œ ì£¼ìš” ë‚´ìš©
- (ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ ì‚¬ì‹¤ 3-4ê°œ)

ğŸ’¡ ì„¸ë¶€ ì •ë³´
- (êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ê·œëª¨, ì¼ì • ë“±)

ğŸ” ë°°ê²½ ë° ì˜ë¯¸
- (ì´ ì†Œì‹ì´ ì¤‘ìš”í•œ ì´ìœ , ì—…ê³„ ì˜í–¥)

ğŸ“Š ê´€ë ¨ ì •ë³´
- (ì¶”ê°€ë¡œ ì•Œì•„ì•¼ í•  ë§¥ë½ì´ë‚˜ ì—°ê´€ ì •ë³´)

ì£¼ì˜ì‚¬í•­:
1. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±
2. ê° í•­ëª©ë‹¹ 2-3ë¬¸ì¥ìœ¼ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±
3. ì „ë¬¸ìš©ì–´ëŠ” ì‰½ê²Œ ì„¤ëª…
4. ìˆ˜ì¹˜ì™€ ê·œëª¨ëŠ” ì •í™•íˆ í¬í•¨

ê¸°ì‚¬ ì „ë¬¸:
{full_content}

ë¶„ì„ ê²°ê³¼:"""

        response = requests.post(
            OLLAMA_API_URL,
            json={
                "model": OLLAMA_MODEL,
                "messages": [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ í•œêµ­ì˜ ì „ë ¥ì‚°ì—… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì „ë¬¸ì ì´ë©´ì„œë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ì„¸ìš”. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”."},
                    {"role": "user", "content": korean_prompt}
                ],
                "temperature": 0.5,  # ì°½ì˜ì„±ê³¼ ì¼ê´€ì„±ì˜ ê· í˜•
                "max_tokens": 1000,
                "stream": False
            },
            timeout=90  # ë” ê¸´ ì‘ë‹µì„ ìœ„í•´ íƒ€ì„ì•„ì›ƒ ì¦ê°€
        )

        if response.status_code == 200:
            result = response.json()
            key_content = result.get('choices', [{}])[0].get('message', {}).get('content', '').strip()
            
            # í›„ì²˜ë¦¬: í˜•ì‹ ì •ë¦¬
            key_content = re.sub(r'\*\*(.+?)\*\*', r'\1', key_content)  # ë³¼ë“œ ì œê±°
            key_content = key_content.replace('ë¶„ì„ ê²°ê³¼:', '').strip()
            
            # ì´ëª¨ì§€ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
            if 'ğŸ“Œ' not in key_content:
                sections = key_content.split('\n\n')
                if len(sections) >= 1:
                    sections[0] = 'ğŸ“Œ ì£¼ìš” ë‚´ìš©\n' + sections[0]
                if len(sections) >= 2:
                    sections[1] = 'ğŸ’¡ ì„¸ë¶€ ì •ë³´\n' + sections[1]
                if len(sections) >= 3:
                    sections[2] = 'ğŸ” ë°°ê²½ ë° ì˜ë¯¸\n' + sections[2]
                key_content = '\n\n'.join(sections)
            
            return key_content[:1900]  # Notion ì œí•œ
            
    except Exception as e:
        print(f"[Detailed Content] ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return generate_key_content_rule_based(content)

# ê¸°ì¡´ í•¨ìˆ˜ë“¤ (í˜¸í™˜ì„± ìœ ì§€)
def generate_one_line_summary_rule_based(content: str) -> str:
    """ê¸°ì‚¬ ë‚´ìš©ì˜ ì²« ë¬¸ì¥ì„ ì¶”ì¶œí•˜ì—¬ í•œ ì¤„ë¡œ ìš”ì•½í•©ë‹ˆë‹¤ (ê·œì¹™ ê¸°ë°˜)."""
    if not content:
        return ""
    
    sentences = re.split(r'[.?!\n]', content)
    sentences = [s.strip() for s in sentences if s.strip()]
    summary = sentences[0] if sentences else ""
    return summary[:200]

def generate_key_content_rule_based(content: str) -> str:
    """ê¸°ì‚¬ ë‚´ìš©ì˜ ì²« 2~3 ë¬¸ë‹¨ì„ ì¶”ì¶œí•˜ì—¬ í•µì‹¬ ë‚´ìš©ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤ (ê·œì¹™ ê¸°ë°˜)."""
    if not content:
        return ""
    
    paragraphs = re.split(r'\n{2,}', content)
    key_paragraphs = paragraphs[:3]
    key_content = "\n\n".join(key_paragraphs)
    return key_content[:1000]

# ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
def generate_one_line_summary_with_llm(content: str, use_llm: bool = True) -> str:
    """ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€í•˜ë©´ì„œ ê°œì„ ëœ í•¨ìˆ˜ í˜¸ì¶œ"""
    return generate_enhanced_summary(content, use_llm)

def generate_key_content(content: str, use_llm: bool = True) -> str:
    """ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€í•˜ë©´ì„œ ê°œì„ ëœ í•¨ìˆ˜ í˜¸ì¶œ"""
    return generate_detailed_key_content(content, use_llm)
